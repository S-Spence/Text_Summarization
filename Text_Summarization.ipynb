{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Summarization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrCnlYyenepI"
      },
      "source": [
        "The notebook below uses the nltk package (Natural Language Tool Kit) to create a summary of online articles. The sample article is a wikipedia article about reinforcement learning. Change the URL to get a summary of a different article. An article by Ekta Shah guided this approach to text summarization. \n",
        "https://www.analyticsvidhya.com/blog/2020/12/tired-of-reading-long-articles-text-summarization-will-make-your-task-easier/."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWWf-pz9VATV",
        "outputId": "c7b3bc2b-925a-46e3-d57b-4f304258ed49"
      },
      "source": [
        "! pip install bs4\n",
        "! pip install lxml\n",
        "! pip install --user -U nltk\n",
        "\n",
        "import bs4 as bs\n",
        "import urllib.request\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4) (4.6.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (4.2.6)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Collecting nltk\n",
            "  Downloading nltk-3.6.5-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 38.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.0.1)\n",
            "Collecting regex>=2021.8.3\n",
            "  Downloading regex-2021.10.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (748 kB)\n",
            "\u001b[K     |████████████████████████████████| 748 kB 71.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.62.3)\n",
            "Installing collected packages: regex, nltk\n",
            "\u001b[33m  WARNING: The script nltk is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "Successfully installed nltk-3.6.5 regex-2021.10.8\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TO9fM3kSYA5i"
      },
      "source": [
        "The code below obtains data through web scraping. The code uses the the BeautifulSoup and lxml libraries to parse text. Swap in another URL to summarize another article. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ggR_Z68XKmT"
      },
      "source": [
        "# Replace URL with another article\n",
        "scraped_data = urllib.request.urlopen('https://en.wikipedia.org/wiki/Hippopotamus')\n",
        "article = scraped_data.read()\n",
        "parsed_article = bs.BeautifulSoup(article, 'lxml')\n",
        "paragraphs = parsed_article.find_all('p')\n",
        "article_text = \"\"\n",
        "for p in paragraphs:\n",
        "  article_text += p.text"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR0P7ip2YaAy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5770fe26-b027-4773-c83f-0db93bb1411a"
      },
      "source": [
        "# Remove square brackets and extra spaces from article\n",
        "original_word_count = article_text.count(\" \") + 1\n",
        "article_text = re.sub(r\"[[0-9]*]\", \"\", article_text)\n",
        "article_text = re.sub(r\"\\s+\", \" \", article_text)\n",
        "\n",
        "# Remove special characters and extra whitespace\n",
        "formatted_text = re.sub(\"[^a-zA-Z]\", \" \", article_text)\n",
        "formatted_text = re.sub(r\"\\s+\", \" \", formatted_text)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: Possible nested set at position 1\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfIeH6rigWZr"
      },
      "source": [
        "The code below creates a word frequency count. The nltk package provides stop words. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WREb0x59di0m"
      },
      "source": [
        "# break sentences into words\n",
        "sentence_list = nltk.sent_tokenize(article_text)\n",
        "# obtain stop words from nltk library\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "word_frequencies = {}\n",
        "\n",
        "# Create a word count of all words that are not stopwords\n",
        "for word in nltk.word_tokenize(formatted_text):\n",
        "  if word not in stopwords:\n",
        "    if word not in word_frequencies.keys():\n",
        "      word_frequencies[word] = 1\n",
        "    else:\n",
        "      word_frequencies[word] +=1\n",
        "\n",
        "max_frequency = max(word_frequencies.values())\n",
        "\n",
        "# Calculate the weighted frequencies by dividing the frequency of each word by te max frequency \n",
        "for word in word_frequencies.keys():\n",
        "  word_frequencies[word] = (word_frequencies[word]/max_frequency)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1S2xaGhjYtK"
      },
      "source": [
        "Calculate scores for the sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_glX5KGhjXtq"
      },
      "source": [
        "sentence_scores = {}\n",
        "for sentence in sentence_list:\n",
        "  for word in nltk.word_tokenize(sentence.lower()):\n",
        "    if word in word_frequencies.keys() and len(sentence.split(' ')) < 30:\n",
        "        if sentence not in sentence_scores.keys():\n",
        "          sentence_scores[sentence] = word_frequencies[word]\n",
        "        else:\n",
        "          sentence_scores[sentence] += word_frequencies[word]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-CKwTLYpuVh"
      },
      "source": [
        "The code below creates a summary using the top n sentences in the sentence scores dictionary. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5-OgEO3lShN",
        "outputId": "4bef00b5-3d0d-4d31-f2be-0171863bca66"
      },
      "source": [
        "import heapq\n",
        "import textwrap\n",
        "\n",
        "# Create a summary of sentences using the top n sentences. \n",
        "summary_sentences = heapq.nlargest(7, sentence_scores, key=sentence_scores.get)\n",
        "summary = \" \".join(summary_sentences)\n",
        "\n",
        "# Format paragraph output\n",
        "summary = textwrap.dedent(summary).strip()\n",
        "print(textwrap.fill(summary, width = 150))\n",
        "print(\"\")\n",
        "\n",
        "# Print orignal word count and summary word count\n",
        "word_count_summary = summary.count(\" \") + 1\n",
        "print(f\"Summary Word Count: {word_count_summary}\")\n",
        "print(f\"Original Word Count: {original_word_count}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hippos inhabit rivers, lakes, and mangrove swamps, where territorial males preside over a stretch of river and groups of five to thirty females and\n",
            "young hippos. While hippos rest near each other in the water, grazing is a solitary activity and hippos are not territorial on land. The earliest\n",
            "evidence of human interaction with hippos comes from butchery cut marks on hippo bones at Bouri Formation dated around 160,000 years ago.  The\n",
            "hippopotamus (/ˌhɪpəˈpɒtəməs/ HIP-ə-POT-ə-məs; Hippopotamus amphibius), also called the hippo, common hippopotamus or river hippopotamus, is a large,\n",
            "mostly herbivorous, semiaquatic mammal and ungulate native to sub-Saharan Africa. Isolated members of Malagasy hippos may have survived in remote\n",
            "pockets; in 1976, villagers described a living animal called the kilopilopitsofy, which may have been a Malagasy hippo. Crocodiles are frequent\n",
            "targets of hippo aggression, probably because they often inhabit the same riparian habitats; crocodiles may be either aggressively displaced or killed\n",
            "by hippos. The common ancestor of hippos and whales branched off from Ruminantia and the rest of the even-toed ungulates; the cetacean and hippo\n",
            "lineages split soon afterwards.\n",
            "\n",
            "Summary Word Count: 180\n",
            "Original Word Count: 4762\n"
          ]
        }
      ]
    }
  ]
}