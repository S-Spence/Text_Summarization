{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Summarization.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrCnlYyenepI"
      },
      "source": [
        "The notebook below uses the nltk package (Natural Language Tool Kit) to create a summary of online articles. The sample article is a wikipedia article about reinforcement learning. Change the URL to get a summary of a different article. An article by Ekta Shah guided this approach to text summarization. \n",
        "https://www.analyticsvidhya.com/blog/2020/12/tired-of-reading-long-articles-text-summarization-will-make-your-task-easier/."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWWf-pz9VATV",
        "outputId": "6f8ad4d1-7e8e-41f9-a275-08ff915541ef"
      },
      "source": [
        "! pip install bs4\n",
        "! pip install lxml\n",
        "! pip install --user -U nltk\n",
        "\n",
        "import bs4 as bs\n",
        "import urllib.request\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4) (4.6.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (4.2.6)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Collecting nltk\n",
            "  Downloading nltk-3.6.5-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 6.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.62.3)\n",
            "Collecting regex>=2021.8.3\n",
            "  Downloading regex-2021.10.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (748 kB)\n",
            "\u001b[K     |████████████████████████████████| 748 kB 43.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Installing collected packages: regex, nltk\n",
            "\u001b[33m  WARNING: The script nltk is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "Successfully installed nltk-3.6.5 regex-2021.10.8\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TO9fM3kSYA5i"
      },
      "source": [
        "The code below obtains data through web scraping. The code uses the the BeautifulSoup and lxml libraries to parse text. Swap in another URL to summarize another article. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ggR_Z68XKmT"
      },
      "source": [
        "# Replace URL with another article\n",
        "scraped_data = urllib.request.urlopen('https://en.wikipedia.org/wiki/Reinforcement_learning')\n",
        "article = scraped_data.read()\n",
        "parsed_article = bs.BeautifulSoup(article, 'lxml')\n",
        "paragraphs = parsed_article.find_all('p')\n",
        "article_text = \"\"\n",
        "for p in paragraphs:\n",
        "  article_text += p.text"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bR0P7ip2YaAy",
        "outputId": "709acc91-a3ba-4453-9e91-9eaaa991edcd"
      },
      "source": [
        "# Remove square brackets and extra spaces from article\n",
        "original_word_count = article_text.count(\" \") + 2\n",
        "article_text = re.sub(r\"[[0-9]*]\", \"\", article_text)\n",
        "article_text = re.sub(r\"\\s+\", \" \", article_text)\n",
        "\n",
        "# Remove special characters and extra whitespace\n",
        "formatted_text = re.sub(\"[^a-zA-Z]\", \" \", article_text)\n",
        "formatted_text = re.sub(r\"\\s+\", \" \", formatted_text)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: Possible nested set at position 1\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfIeH6rigWZr"
      },
      "source": [
        "The code below creates a word frequency count. The nltk package provides stop words. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WREb0x59di0m"
      },
      "source": [
        "# break sentences into words\n",
        "sentence_list = nltk.sent_tokenize(article_text)\n",
        "# obtain stop words from nltk library\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "word_frequencies = {}\n",
        "\n",
        "# Create a word count of all words that are not stopwords\n",
        "for word in nltk.word_tokenize(formatted_text):\n",
        "  if word not in stopwords:\n",
        "    if word not in word_frequencies.keys():\n",
        "      word_frequencies[word] = 1\n",
        "    else:\n",
        "      word_frequencies[word] +=1\n",
        "\n",
        "max_frequency = max(word_frequencies.values())\n",
        "\n",
        "# Calculate the weighted frequencies by dividing the frequency of each word by te max frequency \n",
        "for word in word_frequencies.keys():\n",
        "  word_frequencies[word] = (word_frequencies[word]/max_frequency)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1S2xaGhjYtK"
      },
      "source": [
        "Calculate scores for the sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_glX5KGhjXtq"
      },
      "source": [
        "sentence_scores = {}\n",
        "for sentence in sentence_list:\n",
        "  for word in nltk.word_tokenize(sentence.lower()):\n",
        "    if word in word_frequencies.keys() and len(sentence.split(' ')) < 30:\n",
        "        if sentence not in sentence_scores.keys():\n",
        "          sentence_scores[sentence] = word_frequencies[word]\n",
        "        else:\n",
        "          sentence_scores[sentence] += word_frequencies[word]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-CKwTLYpuVh"
      },
      "source": [
        "The code below creates a summary using the top n sentences in the sentence scores dictionary. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5-OgEO3lShN",
        "outputId": "bc7b431c-aae4-433f-e946-5e2fdaf0eff7"
      },
      "source": [
        "import heapq\n",
        "import textwrap\n",
        "\n",
        "# Create a summary of sentences using the top n sentences. \n",
        "summary_sentences = heapq.nlargest(7, sentence_scores, key=sentence_scores.get)\n",
        "summary = \" \".join(summary_sentences)\n",
        "\n",
        "# Format paragraph output\n",
        "summary = textwrap.dedent(summary).strip()\n",
        "print(textwrap.fill(summary, width = 60))\n",
        "print(\"\")\n",
        "\n",
        "# Print orignal word count and summary word count\n",
        "word_count_summary = summary.count(\" \") + 2\n",
        "print(f\"Summary Word Count: {word_count_summary}\")\n",
        "print(f\"Original wWord Count: {original_word_count}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reinforcement learning is one of three basic machine\n",
            "learning paradigms, alongside supervised learning and\n",
            "unsupervised learning. Research topics include Associative\n",
            "reinforcement learning tasks combine facets of stochastic\n",
            "learning automata tasks and supervised learning pattern\n",
            "classification tasks. In reinforcement learning methods,\n",
            "expectations are approximated by averaging over samples and\n",
            "using function approximation techniques to cope with the\n",
            "need to represent value functions over large state-action\n",
            "spaces. The work on learning ATARI games by Google DeepMind\n",
            "increased attention to deep reinforcement learning or end-\n",
            "to-end reinforcement learning. Policy iteration consists of\n",
            "two steps: policy evaluation and policy improvement. Two\n",
            "elements make reinforcement learning powerful: the use of\n",
            "samples to optimize performance and the use of function\n",
            "approximation to deal with large environments. Assuming full\n",
            "knowledge of the MDP, the two basic approaches to compute\n",
            "the optimal action-value function are value iteration and\n",
            "policy iteration.\n",
            "\n",
            "Summary Word Count: 142\n",
            "Original wWord Count: 3092\n"
          ]
        }
      ]
    }
  ]
}